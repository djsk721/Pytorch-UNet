{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cifar10(batch_size):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainset, trainloader, testset, testloader\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torchvision.datasets.cifar.CIFAR10\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset[0]))\n",
    "print(type(trainset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADNCAYAAAChOisgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlzUlEQVR4nO2de4xdV5Xmv3Vvve1yld8pJyZOJyZPwEmbEAg9HQKBdOjm0SOmw6gRM4Pk/NFIMEIaQo80A/NXWuIxI/UoUmgyhOHRYjphiIA0cQdoiJpOcILzwiTO06n47cR22eV63HvX/FHX03X2+iq1695rVx3x/aTSrbO8zz7rnHtr3+P1nbWWuTuEEEKUj8piOyCEEKI1tIALIURJ0QIuhBAlRQu4EEKUFC3gQghRUrSACyFESWlrATezG83saTN71sxu7ZRTQggh5sdafQ7czKoAngFwA4BRAL8C8FF3/03n3BNCCDEXXW3sezWAZ939eQAws78F8EEAcy7gAwMDPjw83MYhhRDid499+/Yddve1qb2dBfxcAC/P2h4F8LbX22F4eBjbtm1r45BCCPG7xxe+8IWXmL2dGLgRW4jHmNk2M9thZjvGx8fbOJwQQojZtLOAjwLYOGv7PAB700Hufoe7b3X3rQMDA20cTgghxGzaWcB/BWCzmV1gZj0AbgZwb2fcEkIIMR8tx8DdvWZmnwTwYwBVAHe6+1Md80wIIcTr0o6ICXf/EYAfdcgXIYQQC0CZmEIIUVK0gAshRElpK4Rypvj2D+8vbJvFJxa7uqLrvdWeOK5S/I6qVON3Fpuf5aeyfauJH+nxAMDIbBU0oo34UW0U961WqmGMV+J+dYvHbCR+RA+ARiPuV6vFkbXadDxmoziui71v5JahGk8J3d3sWifvZdyN2rqI9c1vuoqMLHLLLbcE2+TkZLCxz09qazTY1Y7kjkvJzaiukovd6jFz/agkfxM516ud+dNtgJ8jO2a6Lzsem4sdk+2b2u68884wZiHoDlwIIUqKFnAhhCgpWsCFEKKkLMkYeCUJHbHomJFYrVuMTaUWI/FiGgtj8WgSP0xj3jS+x86AhSxpHDONycURbP6qxe/m9JzSmDgA1KgPtWBpNEjcfbp4tRvk/qBOYoWVapxruh69sErR2GhMxflJbL7LSJA9A/Zednd3tzRXqzFSIC9u3U4cOydG3U4suNX5c2PlqS13P3Zdc2LxuTpCbly/HXQHLoQQJUULuBBClBQt4EIIUVK0gAshRElZkiJmKsBVafINSWjJEFoqDTIXEdGMiDGMRnJMmlxCRI8qiLDGRKFEoKSCrpNzciIUZYg9DSIEs+SbRpVc67q/7jYANDKvf52J1Mm1rrNz9HhdWSJSq7TagjBX5GICWb0eFd3UliuS1mpRkE6T4thcbD9Gznmy+RlsHLtm6bVg14vNxcal1yxXEM0VkXPPPRfdgQshREnRAi6EECVFC7gQQpSUtmLgZvYigDEAdQA1d9/aCaeEEELMTydEzHe5++EOzPP/SQvpVZjg5yTrkghf6SgmNlDRgwmP3cSWVAdk4me9Ho/ZXYmXvkqrIs4vYpJLkZX9WXci4pD5iftwIiCm/6FrkPnrNKuTTEWqKVYTsbPBhGziVq4gHfZrI5Mup6pdrq3Twtd8x8zNisyZi9GqOAnwv9/0mEwIZuT4mvse5cLOqR0UQhFCiJLS7gLuAO43s0fMbFsnHBJCCJFHuyGUa919r5mtA7DdzH7r7j+fPaC5sG8DgKGhoTYPJ4QQ4jRt3YG7+97m60EA3wNwNRlzh7tvdfetAwMD7RxOCCHELFq+AzezZQAq7j7W/P29AP5bJ5xKK6E2PApfTgTLOhuXZlaRlmSVerR1d/URz4hollxBkqCIOlEZ6xWSEUcyEpG2i6LaJPkeztBZmOhLC9oSo5NysrVa0TZNMjHdiIhJlEcm6FYS0ZJpezUmcnUuETNb4EvFqnZaqjFRLkckzS3b2irM15xMTCbktZPdmGaS5magMnLE2naE5k4L0u2EUNYD+F7zhLsAfNvd/74jXgkhhJiXlhdwd38ewFs66IsQQogFoMcIhRCipGgBF0KIkrIky8mmEgETLGmGFJss0SSYcMeSFlk5U6ux8qiJWEUUP9aHkwmu7Pu0mpxVjtAJAM6bbha3SLYjiDjJ0hvZdUwzNhvkwjKvmBtVci08aXdZRxTDaizTrUXdrlWRDoifz1xBLlfMyxHDcoW7HHJ7YuaIgLnnk5sFmc7XTv/O1P9Oi8MqJyuEEAKAFnAhhCgtWsCFEKKkLMkYOJIWYTzWRuLFJNacxoIbLETKQsGssmGF+MFixgk07kVD1CyuP39szUgQmYUiY9W5eD7T5LxZR7Jpsm8Mlc9fsXAhpFUdG+y8Wey8xePltjzLiW/nxnjZuOnp6WDLifu2Wvmu1dgzkHeeuXO1ek6dTGBqpxph7nveDroDF0KIkqIFXAghSooWcCGEKClawIUQoqQsSRHT0qp/NPDPKsDNL4SwVmBU9CC6VE7iAp2LVOWzbtb7a37f2PxMxGyEZnJMEGVJTSzpiAibREyqhXFEBKx0Bxu7i+AVBJP3kqcFzbtfLlNTU8H22muvBdvJkyfjEZNr0d/fH8YsW7Ys2Hp7e4MtrbYHRGGTfTZZIg8TRFOxjR2vHfEtPSYT93LboDFyhE12zJy/51zBlfnP/1Zbb9PH0B24EEKUFC3gQghRUrSACyFESZl3ATezO83soJk9Ocu2ysy2m9nu5uvKM+umEEKIlBwR8+sA/hrAN2bZbgXwgLvfZma3Nrc/2ymnqtVU6GIZTUSkI2KGB1GLCAvkMmRnT2ZUO3QmKE4RlY5kklZRvBasch+rFsgqIKZCS4OdEJuLVUAktlSspcIXEXSpeEv8iOT+B7I1Ae6ee+4JtldffTXYJiYm4hGTc+/ujuLtihUrgm3VqlXBtnJlvD/q6yu2/GP9Zplwmu7HfGXkiphMUEz3ZYJfbps1Rk6Fv5y2dMyPXME1N2PzrGdiNrvMp5/aDwK4q/n7XQA+1FGvhBBCzEurMfD17r4PAJqv6zrnkhBCiBzOuIhpZtvMbIeZ7RgfHz/ThxNCiN8ZWl3AD5jZCAA0Xw/ONdDd73D3re6+lcXphBBCtEarmZj3Avg4gNuar9/vmEfIbTtEMreYKJFmYrIMP1Ka1oKQOkeWZaIqTk7HrLzBFVFMesOGkWC7ePPmYFudilrkBF47diTYnnv+uWA7dLgoZbiR0qgkm7VWJyKysY9OkrnISoSyDFqizGZJPZmZbjkleRlDQ0PBNjk5mWU7duxYYZtla+bChK+enp7CNsvqHB4eDrbVq1cH2/LlywvbTDRlgmu6H/MLiH/Pue3lckXAVCDOaZUGcOE03Tc3QzS3FV6nyXmM8DsAfgngYjMbNbNPYGbhvsHMdgO4obkthBDiLDLvHbi7f3SOf3p3h30RQgixAJSJKYQQJUULuBBClJSlWU42EQRyRQlUSEnHJDPSWV9LJoax/prkkAP9xWO+723vDGP+4Jqrgu2KSy8LtuGh4WDr6ysKoF09UVydmo5lQ18afSXYfnj/9sL2T/7xF3GuyVhulJXzZb1FU63QiHjIREyWnJaViElgx2yVt771rcF29OjRYBsbGwu2NGNzdHQ0jGGladn8hw8fDrZUJN27d28Yk9tzMxUBmTjJBF0mkjIBdN26dfOOYU+osbK2jLQELxNSWSYsEyhzRMvcXql5D2O0h+7AhRCipGgBF0KIkqIFXAghSsqSjIFXklg2C3ezh+S7WGwqTRIhSTsVYqtVSNy3EltsfeSm9xa2/+ym68MYTJwKpoF6jDX3TZBkj1Mnin5V41u2fHh9sF3+xhhjv/iiNxa2161eE8Z881vfCbaaxWtdIRpBI6MTnpNqja22nmJVHlk1yFZjkaz9GIuvsuSYND48ODgYxrCWZ+y8WVz84MFi8jOrknjo0KFgY+NOnCh+xo4fPx7G7NmzJ9hyY8ipjVVEZJUT2TVL4+m587O4Pouxp7F4lsDE9mMxduZHO63jGLoDF0KIkqIFXAghSooWcCGEKClawIUQoqQsSREzzfVgwk5XN3OdCGSJbXoqClMNJ+2cyOzXXHlFsF18blFU+cbtt8f5Sfu0yy99U7AxgWxystiuq05EujdsviTY1oxsCLZVI2sL2zf/yfuir6diUspd/ycWm5z0eP3TJB0nFSOrnifisCSU9HPAu8t1LpGHCeWsgh0bl1YoZGNY8goTw1jiy/r1ReGazc9E2FdeiQleqSDKRMxcmB9pEhNLYGLJUOzvgYmpqY2tF+y6MnE7JymI7ZcrbKZi6jnnnBPGLATdgQshREnRAi6EECVFC7gQQpSUnIYOd5rZQTN7cpbt82b2ipntbP7cdGbdFEIIkZIjYn4dwF8D+EZi/4q7f7HjHiGKEKwyYKVKvnuIwNSVZD6tWhszq1gm3QUXbAq2P7x6S7A99OOiwHffff8YxqxYEwXFXz/xQrAtWxaz0ZYvL2aj9fX3hjEv7d8XbBdetCn6saIooJx3bhRQbv7w+4Pt+dFY6e7+f3o02CpJG7pGFxEU03RNcMGStXZLx9VJezmj8nNr5AqDzP+UVBybaz9mO3UqZvLmtCljWYRMLEzn2rAhfl5HRmILQFZh8dlnnw22NPuQCYOssiE75ksvvRRsqWDMzvuCCy4INiYip9mTbAwTMVlbPSampp8DJoovhHnvwN395wBi/q0QQohFpZ0Y+CfN7PFmiCU+5ySEEOKM0uoCfjuACwFsAbAPwJfmGmhm28xsh5ntGB8fb/FwQgghUlpawN39gLvX3b0B4KsArn6dsXe4+1Z338riSUIIIVqjpUxMMxtx99PK2YcBPPl64xdKWqqUiQGsLOmGNVGMXJcIlD19UShctz6KJRXS0+vub98TbIdGdxe2G72xbOWeI1E4Gnv1QLBtPO+8YBupFEWPwa4ohtUOR4miRr6a33z5xYVtr0fhZeJwFEQ/dMO7gm33i1HAeuVQsc2Xk6zLGtFsqJhHBNB0HMv0ZHJig4idOTDBkpGTncmErxzxcy7SfVnWH/OfCaKpr0xQZOfIytW+8EIU51kJ25SLLroo2Fh248mTseRyem1ZGdfNmzcHGxM703NnQiorA5y2uAP4ujUxUcysfuaZZ8KYhTDvAm5m3wFwHYA1ZjYK4L8CuM7MtmDm7+VFALe05YUQQogFM+8C7u4fJeavnQFfhBBCLABlYgohREnRAi6EECVlaZaTTcgVe9Ysjz30Th4oCi2jx6OIs+uRp4Nt/6GDwdaoxzKb61YVRcXh9bHP5IHnouA3bVEUmiI9Hl8bK/YrPHL8RBgzWYvn9NLwULAdOlwUWnpvfGcY46Tcbo9Hgeztb7k82H74k38ubDfIfjVS7pVlEbKGmqmlTpIunciY043Wst2Y8MhsrM9hOi63FyITvtgxUzGS7ZdbFjYnU5L9DbI+k+w8U9Fv1apVYcyll14abGmZW4CLmOm5s/mXLVsWbKmgyOZigiXLumSCMROW2b7toDtwIYQoKVrAhRCipGgBF0KIklKOGDhJ2ql2xVjbCy/GSmXVyST+WYlxqa5KjPmtXR3LuwyuiolCUyeLcbpqJcZzhwZJ8tCamETwho3nB9v4eDFmdmIsxgCnp+P1eWnP/jjuVDFOt3JVzL/6wzfHhIcui9f6SpIY8ehjzxW29x+J8fqeaozVNsj76yQuXkti2UwzqJNqhJUWKxQ+99xzwcbiylNTU8GWZh2z2DBLJGE2Ft/u7y9+pphfrHIf8yONebOWZ8wvNheLK6dxZLYfS/Z56qmnsuZPqydu3LgxjGFJQSw5Ka0WyGLgrLIku/5MN2D6QjvoDlwIIUqKFnAhhCgpWsCFEKKkaAEXQoiSsiRFzHrSTitXghonAllloHiKrOVWN9mvalFsWLM+JgisGy5WEPztk7vCmBUkiYB0FsNUPQomPf3FymrLiQBUN1bpLo47eLRYFXHnrtj+yk9F4fH8NcPB9pa3nxtsWy5/Y2H7x7/YEcZ0d8VKcbR1GRGP0jPqJu+lkUQelgiTw7333htsTKxi86eiGUvqyBUxWcJMOo6JdEyMZAknQ0PFpC/WYpAJoqyl2okT8fOTipZMiHzssceCbd++WBmTJemwSoYpua3LcsblJngxOl1SW3fgQghRUrSACyFESdECLoQQJWXeBdzMNprZT81sl5k9ZWafatpXmdl2M9vdfFVjYyGEOIvkiJg1AJ9x90fNbBDAI2a2HcC/A/CAu99mZrcCuBXAZzvhVCo0Vmj2XhS+GlVSKS6tCkeO10AULox8t+3dF1tInbNyU2F747kxm7JWj+3TJixWJWvQhmBF22ukddOxY0eDbc3qdcH26qtFUevlA9GvhseswhWDUUQ7cuDlYLtsczED7qEnfhPGTEyR9yhYAHTHj2aandlFBKc0WxMAvNJaJuY111wTbKx1FhPlxsaKgvHhw4fDmP37Y7YsEwtzRDOW4ZdbVTAdt3JlvBdj4mduZb2cCn/sGrLzZiLm4GCxCimbi503EyzTc2I+MKGW2XKqSLbLvHfg7r7P3R9t/j4GYBeAcwF8EMBdzWF3AfhQRz0TQgjxuiwoBm5mmwBcCeAhAOtPNzZuvsZbPiGEEGeM7AXczJYDuBvAp909r1L8zH7bzGyHme0YHx9vxUchhBCErAXczLoxs3h/y93vaZoPmNlI899HAMT2GQDc/Q533+ruWzv9ELsQQvwuM6+IaTMKxNcA7HL3L8/6p3sBfBzAbc3X73fKqWpX8XvFSKYhbT1FxvUkQkIX2Y+JaEZKqDY87rtvf1HUuuSiWGb12IkouO5+mWRBkuzJiYnif3b6+2MmY3dXFHaciHl9/cUymBVy4vVq/JI9PsXK+cbMwnOGi7696dJNYczDjz8fbD09sTxnF3lX0rKzjWmSNUdKu7baUu3aa68l08f5mUCWilWvvPJKGMNahjExLEeAY3MxQZQJd+kDAXv27Alj+vrI545kl7JSsen8bExumzKWXbprVzH7mc2Vey1S33Jb3OW2fUzP6ZJLLsnaby5ynkK5FsDHADxhZjubtr/EzML9XTP7BIA9AD7SlidCCCEWxLwLuLs/iLnLkby7s+4IIYTIRZmYQghRUrSACyFESVmS5WSrSeYly4qsGMnUM5KdmQR/nJV9JOIniHjRRUTM4yeLWWVTHv1auWZtsI2Rfn+nxqNo40mW6CTJ5BpcMRhs4xOxd2bFiqJTFVE89Hq8Fi+8FMuGDlWjaLPl968obF96/kgYs+vpKCY1SG9LJyJyzdLPRaTSIO/lZLyuOTCxKle4S0vArlsX0ySYiMZEUpZ1nIprrKfk9u3bg20ZKW2c+sFEQLbfmjVrgo09KpyWimXZlOyYTJhl86fC79q18e+NiZFMmM0pJ8tK/rLPBXvfWi1tPBe6AxdCiJKiBVwIIUqKFnAhhCgpWsCFEKKkLEkRM9UUu4lIVK0Q1+nT6kWxzUjCFBM4qI0IENNJH8vRfTHjbjURbUY2bAi2vXujWDi8siiY9PbGEqGvHY8lTpcNRmGzpzsVbUgqJjnvGhFjqj3x+tdrRSFq/coo3P3+lsuC7eFHn4hu9EWBNa366/Uo+OX0p8yFZdcxW06p1XYy+ti+aUnWtKQqALz//e8PNiaspaVu2VxMxGTCHeuTmYqYTARkGYlMxHzooYeCLX1/3/GOd4Qx558fyzyz65oK0uw9YmV6mfjMBNFUhH366afDmIWgO3AhhCgpWsCFEKKkaAEXQoiSsiRj4PV6MaZIW0qR755qNcbk0iiXNVjVsBgLo83NSGuuehJSPDkeE23WrY+XuXegP9jWnBNjxj1JrLnBqgwujxUEB5bHmGVPTzEG3t1FKsyRuGBjKsbYDxyJ7dh6nime+xVXRR/+6Lqrg+3VI7Hd2LP7YmJKpVr01zPjyq3GwHPbX+XEylm8NTfezeLWacyVjWHnzY45NDRU2GYxXjY/i/2zWHBaRjp3LhZ3Z+3eclq7sflz3hN2vdg55iZ4sfh/O+gOXAghSooWcCGEKClawIUQoqTMu4Cb2UYz+6mZ7TKzp8zsU037583sFTPb2fy56cy7K4QQ4jQ56k4NwGfc/VEzGwTwiJmdLnP2FXf/YqedqjeKSQpWm6ufRBGWaFNN+oal2wBQZWIGm7/KqhYmI8mQXlL1bCVJ7unqjr5NTU8UtutJ4hAALCfn3U8E3alTSXIJefcrRIw5MTYWbM9P7Q+2zW94a2G7r0EqJyK2DPvX778u2L75/QeCbc/Boh/dPdFXZAqDOTBxLE2gAbiAlcKSOnIThXJ8y52L+ZFeHyb45QqbTERevXp1YXv9+vVhTH9/FPUZIyOxwuX+/cXPIvPr6NGjwZYjbrNryPZjgiW7Zp2uRpjTkWcfgH3N38fMbBeAczvqhRBCiAWzoK8DM9sE4EoAp/NZP2lmj5vZnWYWn+8RQghxxshewM1sOYC7AXza3Y8DuB3AhQC2YOYO/Utz7LfNzHaY2Q5WjF0IIURrZC3gZtaNmcX7W+5+DwC4+wF3r7t7A8BXAcQMjZlxd7j7Vnffmj7QL4QQonXmjYHbjMLxNQC73P3Ls+wjzfg4AHwYwJOdcsoToahOWpk5scHj91FvVyIkdLHKgyTTkwmWVXLMRlG8mKaV+6KYcQ6pRljfF/c9uOdQ0S/iwoq++MVYn45i21QifE1OxIyyU0TwO3U8ZkWu3xgr1g0OFbPMNpwfz/HoyZh1OTwYRa1/84Ebgu3uH/2ssD06+loYU2XZhxltshgTExPBxkRMJvqlYhXbjwlaTIBjQlo6HxNc2VxMxEwFuFzhjonDLEvxwgsvnNeHI0eOBBu7Ziw7M600yPw/dixmE7Prn54TO8fe3lgpk/mV0wqvXXKeQrkWwMcAPGFmO5u2vwTwUTPbgpkHNl4EcEtHPRNCCPG65DyF8iB4pe0fdd4dIYQQuSgTUwghSooWcCGEKClLspysJbH/hkfRo9EgYmSdtEiqJWU9u0n2WE8UJbq7WNZlNNUTUaKbtAKzrpipNz4Zha9DR6JYOFErikJmJJNuKjrWbTEz7ORk8THOGsnqHCQCzdEDe6NfK2Lp2+la0bd1my8OY3rGSGnaF+L8l2+KLbY2/IePFba//Z0fhjE7dscWVY0Wb1OYiMYEODYuFbByRUwmcrFjpvOzMczGRMZ0rtxsUOY/mz89Jya4MiGYXbMcgZXNn1u6N82q7SNZ1Oy8c31lGZvtoDtwIYQoKVrAhRCipGgBF0KIkqIFXAghSsqSFDEHktKSNfI9k/aiBIAKokCQChW0H18tCiheIWJnxvxdTLA8FTP6DuyPGYkVi/uuXF6sEeaIYsmJ8VjuNZ4RMH6iKCAeOxxF07G+eI7d5Fr0EeF35y9/VdjefNHmMGbdhnOC7dSRmFE5tTYKUSsT4fTP/+2fhjGDP/mHYHvgwQeDLQfWE5OJbYxU1GKCIstuzM3eS225ImmO4Jor+OXMBcSMVnYNc8vhMpE09YOV92XXggmK6fvEPgOd7GXaLroDF0KIkqIFXAghSooWcCGEKClLMgY+XUvblJEEnWp0vZt8H1WS2BSLe7H4WJ0E2T1tn4ZY/Y7NPz0V47m9pELhBKmK6PXiMavkWhwlVfMaJK5fS+qx95O43auHDwXb8IoY725Y9P83O39T2P5R5VthzOZLzg+2Snec/4JLLwy2nQ8/Vti+5Iqrwph//2d/HGzTk0eD7bX9MaEo5fjx48HG4r7sPU9jne3EwHMSa9j8rKUXI6cCHyM3eSX1LTcGzvxg49Jr1qpOAcS1gPmQ21Itt4JjO+gOXAghSooWcCGEKClawIUQoqTMu4CbWZ+ZPWxmj5nZU2b2haZ9lZltN7PdzVc1NRZCiLNIjog5CeB6dz/R7I35oJndB+BPATzg7reZ2a0AbgXw2U44NTGeiH7VKNBUiOcN0vKsK60WmFlpzchcDbZrRruuOhGm+vrid+epahyX6iA1IogOEGFzkhxzfKoodhoRZft7o/B1fCyKpE88Mxpsv7dmTWF7qhaFnX2jB4PtTVuvCLaTh/cE24ZVxQSN3Y/+Ioy56g/eFWwfed/1wXbHXd8LthSWxMEEb2ZLYeJbbpJITqXBXOGOiW2pCJgr3DGRlF2LdBybK7dyIjtmTmVGJg4zcgRddq3Z/Oxas3Zs7TDvJ89nONHc7G7+OIAPArirab8LwIc66pkQQojXJbcrfbXZD/MggO3u/hCA9aebGjdfY4HomX23mdkOM9sxnjzGJoQQonWyFnB3r7v7FgDnAbjazOL/eefe9w533+ruWwcGYvd0IYQQrbGgp1Dc/SiAnwG4EcABMxsBgOZrDG4KIYQ4Y8wrYprZWgDT7n7UzPoBvAfAXwG4F8DHAdzWfP1+p5yqJCJHw/Oyl5yojJ58ReWKGXR+lgWWCCZp5ufMmCjGVCxmgfX2EjFyqjiuh1QGHCDHnJyOx3QU950kmWiDg4PB1j0Z20qNHj4abL3J+9a7L2Yy/vOOKH6ibyiYJk/G8xwcWlHYPvxqrOj4zED0df2FsT1bDmkVPSBfhEqz/HLbszFYdb1UCMwV7nIyHtl5s/2YoJiT6ZybldpqBUTmK2uNxo6ZCpTM11xhMzdjsx1ynkIZAXCXmVUxc8f+XXf/gZn9EsB3zewTAPYA+EhHPRNCCPG6zLuAu/vjAK4k9iMA3n0mnBJCCDE/ysQUQoiSogVcCCFKypIsJ5uKmEzCJNVkUSVipyV755SjBIAKK+1KHLFGUeRY1hsFp4FuUm60K05WWRaFlldPFseNnYrP0tdI6dsqaXmGrqLo1F2PItTYsZPB1j8Y/RocXh5sh44XS7Q2yDU8fCJmH/7gvp8H2wfe8dboW73YOm7l8niOQ6Qt3chFFwRbDseOxZKzTAxjwmb6mWLiG9svZy4gCo3tlGNNx7FzzBUGmbCZ7svyQZhYyI6ZU4qWnTfL6swRkdn7wURldszc0tXtoDtwIYQoKVrAhRCipGgBF0KIkqIFXAghSsqSFDG7EiEkV6DprkTRIK2YWiPCxcRkFDhoOVmQLE4vilPdtOxmtLFvzpNjJ4LtVCJa1mpMeInXZ2g4lmefTHS0k9NjYQzrBXpyPAqPq1YPB9tU8j5Nk2s9tHpVsI2fiuf98ujeYNt08cbC9sUja+P8pBfo87/8p2DLob+/P9hyM+lyxKrcEqpMuJucLJYVZiJpbv/FdBw7RzZXbqZnOh8TOtk5smvB/EjL8jIfmBjJ3t/0nFjJX2Zj1yznWrTbI1N34EIIUVK0gAshREnRAi6EECVlScbA33PtmxfbhY4yNRmTY1YMr8iyAW88Ax6VkwPpduwuN9MAMGWMGeeHxTBZrJnZcmBx31Zbo3W6yl0OnbwWDFbNj9lYLPt3Bd2BCyFESdECLoQQJUULuBBClJR5F3Az6zOzh83sMTN7ysy+0LR/3sxeMbOdzZ+bzry7QgghTpMjYk4CuN7dT5hZN4AHzey+5r99xd2/eObcE0IIMRc5HXkcwOlUue7mT5TnhRBCnFWyYuBmVjWznZjpPL/d3R9q/tMnzexxM7vTzGLu9sy+28xsh5ntYHWAhRBCtEbWAu7udXffAuA8AFeb2RUAbgdwIYAtAPYB+NIc+97h7lvdfevAwEBHnBZCCLHAp1Dc/SiAnwG40d0PNBf2BoCvAri68+4JIYSYC2PZZoUBZmsBTLv7UTPrB3A/gL8C8Ii772uO+Y8A3ubuN88z1yEALwFYA+BwB/xfLOT/4iL/F48y+w6U1//z3T2U38x5CmUEwF1mVsXMHft33f0HZva/zWwLZgTNFwHcMt9Epx0wsx3uvnUBzi8p5P/iIv8XjzL7DpTf/5Scp1AeB3AlsX/sjHgkhBAiC2ViCiFESVmsBfyORTpup5D/i4v8XzzK7DtQfv8LzCtiCiGEWJoohCKEECXlrC/gZnajmT1tZs+a2a1n+/gLpZlletDMnpxlW2Vm281sd/OVZqEuNma20cx+ama7moXIPtW0l8X/uQqplcL/0zQzmX9tZj9obpfGfzN70cyeaBas29G0lcn/YTP7OzP7bfPv4O1l8n8+zuoC3nwU8X8C+CMAlwH4qJlddjZ9aIGvA7gxsd0K4AF33wzggeb2UqQG4DPufimAawD8RfN6l8X/04XU3oKZjN8bzewalMf/03wKwK5Z22Xz/13uvmXW43dl8v9/APh7d78EwFsw8z6Uyf/Xx93P2g+AtwP48aztzwH43Nn0oUW/NwF4ctb20wBGmr+PAHh6sX3MPI/vA7ihjP4DGADwKIC3lcl/zJSfeADA9QB+ULbPD2ZyPNYktlL4D2AFgBfQ1PrK5n/Oz9kOoZwL4OVZ26NNW9lY780s1ObrukX2Z17MbBNmnud/CCXyf45CaqXxH8B/B/CfADRm2crkvwO438weMbNtTVtZ/P89AIcA/K9mCOtvzGwZyuP/vJztBdyITY/BnGHMbDmAuwF82t2PL7Y/C8F5IbVSYGZ/DOCguz+y2L60wbXufhVmwp5/YWb/arEdWgBdAK4CcLu7XwngJMocLiGc7QV8FMDGWdvnAdh7ln3oBAfMbAQAmq8HF9mfOWk24bgbwLfc/Z6muTT+n8ZnFVJDefy/FsAHzOxFAH8L4Hoz+ybK4z/cfW/z9SCA72GmaF1Z/B8FMOr/Uv767zCzoJfF/3k52wv4rwBsNrMLzKwHwM0A7j3LPnSCewF8vPn7xzETW15ymJkB+BqAXe7+5Vn/VBb/15rZcPP3fgDvAfBblMR/d/+cu5/n7psw81n/ibv/OUriv5ktM7PB078DeC+AJ1ES/919P4CXzezipundAH6DkvifxSIICzcBeAbAcwD+82KLABn+fgcz9c6nMfON/gkAqzEjTO1uvq5abD/n8P2dmAlRPQ5gZ/PnphL5/2YAv276/ySA/9K0l8L/5Fyuw7+ImKXwHzMx5MeaP0+d/nsti/9NX7cA2NH8DP1fACvL5P98P8rEFEKIkqJMTCGEKClawIUQoqRoARdCiJKiBVwIIUqKFnAhhCgpWsCFEKKkaAEXQoiSogVcCCFKyv8DFvEGxCJFRTYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습데이터 가져오기\n",
    "trainset, trainloader, testset, testloader= make_cifar10(2)\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 정답(label) 출력\n",
    "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def add_gaussian_noise(image, stddev=0.2):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to an image tensor.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor (batch_size x channels x height x width).\n",
    "        stddev (float): Standard deviation of the Gaussian noise.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Noisy image tensor with values clamped between 0 and 1.\n",
    "    \"\"\"\n",
    "    # Generate random noise with the same size as the image\n",
    "    noise = torch.randn_like(image) * stddev\n",
    "\n",
    "    # Add the noise to the image\n",
    "    noisy_image = image + noise\n",
    "\n",
    "    # Clip the pixel values to be in the range [0, 1]\n",
    "    noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_image(original_image, noisy_image, prediction_image):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image.squeeze().permute(1, 2, 0).numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Noisy Image\")\n",
    "    plt.imshow(noisy_image.squeeze().permute(1, 2, 0).numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Prediction_image\")\n",
    "    plt.imshow(prediction_image.squeeze().permute(1, 2, 0).numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(batch):  2\n",
      "batch[0]:  tensor([[[[ 0.1373,  0.2157,  0.2314,  ...,  0.0980,  0.1294,  0.1529],\n",
      "          [ 0.0196, -0.0196,  0.1451,  ..., -0.3176, -0.1765,  0.0196],\n",
      "          [-0.1059, -0.1137,  0.0039,  ..., -0.4980, -0.3569, -0.2000],\n",
      "          ...,\n",
      "          [ 0.5843,  0.6157,  0.6235,  ..., -0.0431, -0.1059, -0.0275],\n",
      "          [ 0.5529,  0.6235,  0.6157,  ..., -0.2549, -0.1451,  0.0745],\n",
      "          [ 0.5529,  0.5765,  0.6078,  ...,  0.1686,  0.4667,  0.6392]],\n",
      "\n",
      "         [[ 0.4275,  0.4980,  0.5137,  ...,  0.3647,  0.3804,  0.3961],\n",
      "          [ 0.2627,  0.2392,  0.4118,  ..., -0.0588,  0.0667,  0.2314],\n",
      "          [ 0.1059,  0.1294,  0.2706,  ..., -0.2784, -0.1373,  0.0196],\n",
      "          ...,\n",
      "          [ 0.3961,  0.4196,  0.4353,  ..., -0.2078, -0.2863, -0.2078],\n",
      "          [ 0.3490,  0.4118,  0.4039,  ..., -0.4196, -0.3176, -0.0980],\n",
      "          [ 0.3176,  0.3333,  0.3725,  ..., -0.0196,  0.2627,  0.4275]],\n",
      "\n",
      "         [[ 0.8275,  0.9216,  0.9529,  ...,  0.7176,  0.7961,  0.8824],\n",
      "          [ 0.5373,  0.5451,  0.7490,  ...,  0.0196,  0.2549,  0.5765],\n",
      "          [ 0.2706,  0.3255,  0.5137,  ..., -0.2392, -0.0980,  0.0902],\n",
      "          ...,\n",
      "          [ 0.1294,  0.1529,  0.1686,  ..., -0.2471, -0.3647, -0.3333],\n",
      "          [ 0.0902,  0.1529,  0.1451,  ..., -0.4275, -0.3647, -0.2078],\n",
      "          [ 0.0745,  0.0902,  0.1294,  ..., -0.1843,  0.0902,  0.2314]]],\n",
      "\n",
      "\n",
      "        [[[-0.5373, -0.4510, -0.3412,  ..., -0.5608, -0.6000, -0.6549],\n",
      "          [-0.4510, -0.4118, -0.2863,  ..., -0.4980, -0.5373, -0.6000],\n",
      "          [-0.5843, -0.5686, -0.6157,  ..., -0.4902, -0.5294, -0.5843],\n",
      "          ...,\n",
      "          [ 0.5843,  0.5686,  0.5765,  ...,  0.3647,  0.4588,  0.6627],\n",
      "          [ 0.4902,  0.4902,  0.5059,  ...,  0.1843,  0.2941,  0.5843],\n",
      "          [ 0.4902,  0.4745,  0.4824,  ..., -0.2471, -0.1137,  0.2235]],\n",
      "\n",
      "         [[-0.5529, -0.4667, -0.3490,  ..., -0.6314, -0.6549, -0.6941],\n",
      "          [-0.4588, -0.4196, -0.2941,  ..., -0.6078, -0.6235, -0.6706],\n",
      "          [-0.5922, -0.5765, -0.6157,  ..., -0.6235, -0.6471, -0.6784],\n",
      "          ...,\n",
      "          [ 0.7333,  0.7098,  0.7020,  ...,  0.2157,  0.3333,  0.5451],\n",
      "          [ 0.6706,  0.6706,  0.6627,  ...,  0.0824,  0.1922,  0.4745],\n",
      "          [ 0.6863,  0.6627,  0.6549,  ..., -0.2627, -0.1373,  0.1765]],\n",
      "\n",
      "         [[-0.7333, -0.6784, -0.5765,  ..., -0.7569, -0.7804, -0.8275],\n",
      "          [-0.6784, -0.6706, -0.5608,  ..., -0.7255, -0.7490, -0.8039],\n",
      "          [-0.8039, -0.8118, -0.8745,  ..., -0.7412, -0.7725, -0.8118],\n",
      "          ...,\n",
      "          [-0.0431, -0.0745, -0.0667,  ..., -0.0353,  0.1059,  0.3255],\n",
      "          [-0.1373, -0.1451, -0.1373,  ..., -0.2392, -0.1137,  0.1765],\n",
      "          [-0.1059, -0.1373, -0.1373,  ..., -0.6549, -0.5059, -0.1922]]]])\n",
      "batch[1]:  tensor([7, 2])\n",
      "batch[0].shape:  torch.Size([2, 3, 32, 32])\n",
      "type(batch[0]):  <class 'torch.Tensor'>\n",
      "batch[1].shape:  torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in trainloader:\n",
    "    if i== 1:\n",
    "        break\n",
    "    # print(\"batch : \", batch)\n",
    "    print(\"len(batch): \",len(batch))\n",
    "    print(\"batch[0]: \",batch[0])\n",
    "    print(\"batch[1]: \",batch[1])\n",
    "    print(\"batch[0].shape: \",batch[0].shape)\n",
    "    print(\"type(batch[0]): \",type(batch[0]))\n",
    "    print(\"batch[1].shape: \",batch[1].shape)\n",
    "    # images, true_masks = batch, add_gaussian_noise(batch[0])\n",
    "    images, true_masks = batch[0], [add_gaussian_noise(image) for image in batch[0]]\n",
    "    compare_image(images[0], true_masks[0], images[0])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(batch):  2\n",
      "batch[0]:  tensor([[[[-0.4588, -0.5059, -0.5137,  ..., -0.9529, -0.9529, -0.9608],\n",
      "          [-0.4824, -0.4745, -0.4588,  ..., -0.9529, -0.9529, -0.9529],\n",
      "          [-0.4588, -0.4588, -0.4353,  ..., -0.9451, -0.9451, -0.9294],\n",
      "          ...,\n",
      "          [ 0.0118, -0.0353, -0.0039,  ...,  0.3647,  0.4431,  0.4588],\n",
      "          [ 0.0510,  0.0667,  0.0588,  ...,  0.1451,  0.3569,  0.4980],\n",
      "          [-0.0039,  0.0353,  0.0667,  ..., -0.1137,  0.2549,  0.5373]],\n",
      "\n",
      "         [[-0.5373, -0.5686, -0.5216,  ..., -0.9529, -0.9529, -0.9529],\n",
      "          [-0.5686, -0.5451, -0.4588,  ..., -0.9529, -0.9529, -0.9529],\n",
      "          [-0.5608, -0.5294, -0.4275,  ..., -0.9451, -0.9451, -0.9216],\n",
      "          ...,\n",
      "          [-0.1137, -0.1529, -0.1216,  ...,  0.3333,  0.4039,  0.4196],\n",
      "          [-0.0745, -0.0588, -0.0745,  ...,  0.1137,  0.3176,  0.4588],\n",
      "          [-0.1216, -0.0980, -0.0824,  ..., -0.1451,  0.2157,  0.4980]],\n",
      "\n",
      "         [[-0.7020, -0.7333, -0.7098,  ..., -0.9529, -0.9529, -0.9529],\n",
      "          [-0.7412, -0.7255, -0.6627,  ..., -0.9529, -0.9529, -0.9529],\n",
      "          [-0.7412, -0.7098, -0.6392,  ..., -0.9451, -0.9451, -0.9216],\n",
      "          ...,\n",
      "          [-0.3176, -0.3333, -0.2863,  ...,  0.2627,  0.3647,  0.3725],\n",
      "          [-0.2784, -0.2471, -0.2549,  ...,  0.0431,  0.2706,  0.4118],\n",
      "          [-0.3255, -0.2863, -0.2706,  ..., -0.2157,  0.1686,  0.4510]]],\n",
      "\n",
      "\n",
      "        [[[-0.7020, -0.7725, -0.4824,  ..., -0.9294, -0.9373, -0.8980],\n",
      "          [-0.5843, -0.6157, -0.5529,  ..., -0.8353, -0.9373, -0.9451],\n",
      "          [-0.5137, -0.4353, -0.7020,  ..., -0.7176, -0.8824, -0.9216],\n",
      "          ...,\n",
      "          [-0.7176, -0.7647, -0.4824,  ..., -0.6000, -0.5686, -0.1608],\n",
      "          [-0.7098, -0.7882, -0.7412,  ..., -0.7176, -0.7412,  0.0118],\n",
      "          [-0.7804, -0.7882, -0.7804,  ..., -0.5137, -0.6078, -0.1294]],\n",
      "\n",
      "         [[-0.6863, -0.7490, -0.4745,  ..., -0.9137, -0.9216, -0.9137],\n",
      "          [-0.5843, -0.6078, -0.5373,  ..., -0.7882, -0.9059, -0.9451],\n",
      "          [-0.5216, -0.4118, -0.6863,  ..., -0.6235, -0.8588, -0.9294],\n",
      "          ...,\n",
      "          [-0.7961, -0.8196, -0.4275,  ..., -0.6706, -0.6392, -0.2627],\n",
      "          [-0.7961, -0.8275, -0.7333,  ..., -0.6941, -0.7961, -0.1216],\n",
      "          [-0.8353, -0.8039, -0.7882,  ..., -0.6941, -0.8039, -0.3412]],\n",
      "\n",
      "         [[-0.7490, -0.7804, -0.5765,  ..., -0.9294, -0.9451, -0.9373],\n",
      "          [-0.7020, -0.6863, -0.6314,  ..., -0.8588, -0.9294, -0.9451],\n",
      "          [-0.6784, -0.5843, -0.7725,  ..., -0.7176, -0.8824, -0.9373],\n",
      "          ...,\n",
      "          [-0.8510, -0.8745, -0.5686,  ..., -0.7647, -0.7647, -0.5922],\n",
      "          [-0.8431, -0.8667, -0.8353,  ..., -0.8275, -0.8980, -0.4980],\n",
      "          [-0.8824, -0.8431, -0.8510,  ..., -0.7804, -0.8824, -0.6314]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4039,  0.4039,  0.4588,  ...,  0.0196,  0.0039,  0.0118],\n",
      "          [ 0.3647,  0.3725,  0.4353,  ...,  0.0118, -0.0039,  0.0039],\n",
      "          [ 0.3725,  0.3882,  0.4196,  ...,  0.0118,  0.0275,  0.0196],\n",
      "          ...,\n",
      "          [ 0.0902,  0.1608,  0.1765,  ...,  0.1843,  0.1294,  0.1608],\n",
      "          [ 0.1451,  0.1843,  0.1686,  ...,  0.2471,  0.2157,  0.3176],\n",
      "          [ 0.1843,  0.2235,  0.2000,  ...,  0.2941,  0.2392,  0.2706]],\n",
      "\n",
      "         [[ 0.4510,  0.4196,  0.4510,  ...,  0.2627,  0.2314,  0.2471],\n",
      "          [ 0.4275,  0.4039,  0.4431,  ...,  0.2471,  0.2235,  0.2392],\n",
      "          [ 0.4588,  0.4353,  0.4510,  ...,  0.2471,  0.2627,  0.2627],\n",
      "          ...,\n",
      "          [-0.2627, -0.2549, -0.3020,  ..., -0.4196, -0.4353, -0.3961],\n",
      "          [-0.2941, -0.2863, -0.3412,  ..., -0.3255, -0.3333, -0.2471],\n",
      "          [-0.3412, -0.3255, -0.3725,  ..., -0.2235, -0.2471, -0.2235]],\n",
      "\n",
      "         [[ 0.6627,  0.6392,  0.6784,  ...,  0.6784,  0.6863,  0.7020],\n",
      "          [ 0.6471,  0.6314,  0.6784,  ...,  0.6471,  0.6471,  0.6627],\n",
      "          [ 0.6941,  0.6784,  0.7020,  ...,  0.6471,  0.6549,  0.6627],\n",
      "          ...,\n",
      "          [-0.5451, -0.5137, -0.5373,  ..., -0.5451, -0.5608, -0.5294],\n",
      "          [-0.5216, -0.4980, -0.5373,  ..., -0.5373, -0.5373, -0.4510],\n",
      "          [-0.5137, -0.4824, -0.5216,  ..., -0.4824, -0.4902, -0.4745]]],\n",
      "\n",
      "\n",
      "        [[[-0.6549, -0.5529, -0.4902,  ..., -0.4902, -0.5294, -0.5843],\n",
      "          [-0.5843, -0.4980, -0.4745,  ..., -0.4824, -0.5137, -0.5529],\n",
      "          [-0.5294, -0.4196, -0.3961,  ..., -0.4902, -0.5059, -0.5373],\n",
      "          ...,\n",
      "          [ 0.4667,  0.4118,  0.2471,  ..., -0.4118, -0.4824, -0.5059],\n",
      "          [ 0.2784,  0.2392,  0.1922,  ..., -0.4353, -0.4980, -0.5216],\n",
      "          [ 0.0902, -0.0745,  0.0196,  ..., -0.4510, -0.5373, -0.5765]],\n",
      "\n",
      "         [[-0.7804, -0.6863, -0.6000,  ..., -0.5216, -0.5608, -0.6078],\n",
      "          [-0.7490, -0.6706, -0.6235,  ..., -0.5294, -0.5529, -0.5922],\n",
      "          [-0.7412, -0.6392, -0.5922,  ..., -0.5373, -0.5686, -0.5922],\n",
      "          ...,\n",
      "          [-0.0353, -0.0824, -0.0980,  ..., -0.2863, -0.3569, -0.3804],\n",
      "          [-0.0902, -0.1216, -0.0588,  ..., -0.3098, -0.3725, -0.3961],\n",
      "          [-0.0431, -0.2078, -0.0431,  ..., -0.3255, -0.4118, -0.4510]],\n",
      "\n",
      "         [[-0.9059, -0.8902, -0.7961,  ..., -0.6078, -0.6471, -0.6863],\n",
      "          [-0.9216, -0.9216, -0.8745,  ..., -0.6314, -0.6627, -0.6784],\n",
      "          [-0.9608, -0.9529, -0.9059,  ..., -0.6549, -0.6784, -0.6706],\n",
      "          ...,\n",
      "          [-0.6549, -0.6941, -0.8510,  ..., -0.0824, -0.1529, -0.1843],\n",
      "          [-0.5686, -0.5686, -0.5922,  ..., -0.1059, -0.1686, -0.2000],\n",
      "          [-0.2863, -0.3961, -0.2471,  ..., -0.1294, -0.2078, -0.2627]]]])\n",
      "batch[1]:  tensor([6, 6, 4, 3])\n",
      "batch[0].shape:  torch.Size([4, 3, 32, 32])\n",
      "type(batch[0]):  <class 'torch.Tensor'>\n",
      "batch[1].shape:  torch.Size([4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"normal_kernel_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-a839c5d32696>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch[1].shape: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# images, true_masks = batch, add_gaussian_noise(batch[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0madd_gaussian_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# compare_image(images, true_masks, images)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-a839c5d32696>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch[1].shape: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# images, true_masks = batch, add_gaussian_noise(batch[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0madd_gaussian_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# compare_image(images, true_masks, images)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-8699f0d74525>\u001b[0m in \u001b[0;36madd_gaussian_noise\u001b[1;34m(image, stddev)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Generate random noise with the same size as the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Add the noise to the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"normal_kernel_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in trainloader:\n",
    "    if i== 1:\n",
    "        break\n",
    "    # print(\"batch : \", batch)\n",
    "    print(\"len(batch): \",len(batch))\n",
    "    print(\"batch[0]: \",batch[0])\n",
    "    print(\"batch[1]: \",batch[1])\n",
    "    print(\"batch[0].shape: \",batch[0].shape)\n",
    "    print(\"type(batch[0]): \",type(batch[0]))\n",
    "    print(\"batch[1].shape: \",batch[1].shape)\n",
    "    # images, true_masks = batch, add_gaussian_noise(batch[0])\n",
    "    images, true_masks = batch, [add_gaussian_noise(image[0]) for image in batch]\n",
    "    # compare_image(images, true_masks, images)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-0bd4553ccc2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from evaluate import evaluate\n",
    "from unet import UNet\n",
    "from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "dir_img = Path('./data/imgs/')\n",
    "dir_mask = Path('./data/masks/')\n",
    "dir_checkpoint = Path('./checkpoints/')\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model,\n",
    "        device,\n",
    "        epochs: int = 5,\n",
    "        batch_size: int = 1,\n",
    "        learning_rate: float = 1e-5,\n",
    "        val_percent: float = 0.1,\n",
    "        save_checkpoint: bool = True,\n",
    "        img_scale: float = 0.5,\n",
    "        amp: bool = False,\n",
    "        weight_decay: float = 1e-8,\n",
    "        momentum: float = 0.999,\n",
    "        gradient_clipping: float = 1.0,\n",
    "):\n",
    "    # 1. Create dataset\n",
    "    train_set, trainloader, val_set, val_loader = make_cifar10(batch_size)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    # experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    # experiment.config.update(\n",
    "    #     dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "    #          val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale, amp=amp)\n",
    "    # )\n",
    "\n",
    "    # logging.info(f'''Starting training:\n",
    "    #     Epochs:          {epochs}\n",
    "    #     Batch size:      {batch_size}\n",
    "    #     Learning rate:   {learning_rate}\n",
    "    #     Training size:   {n_train}\n",
    "    #     Validation size: {n_val}\n",
    "    #     Checkpoints:     {save_checkpoint}\n",
    "    #     Device:          {device.type}\n",
    "    #     Images scaling:  {img_scale}\n",
    "    #     Mixed Precision: {amp}\n",
    "    # ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                              lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch['image'], batch['image']\n",
    "\n",
    "                assert images.shape[1] == model.n_channels, \\\n",
    "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                    masks_pred = model(images)\n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "                    else:\n",
    "                        loss = criterion(masks_pred, true_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (5 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        histograms = {}\n",
    "                        for tag, value in model.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "                            if not (torch.isinf(value) | torch.isnan(value)).any():\n",
    "                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                            if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n",
    "                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                        val_score = evaluate(model, val_loader, device, amp)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        try:\n",
    "                            experiment.log({\n",
    "                                'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                                'validation Dice': val_score,\n",
    "                                'images': wandb.Image(images[0].cpu()),\n",
    "                                'masks': {\n",
    "                                    'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                    'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
    "                                },\n",
    "                                'step': global_step,\n",
    "                                'epoch': epoch,\n",
    "                                **histograms\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            state_dict = model.state_dict()\n",
    "            state_dict['mask_values'] = dataset.mask_values\n",
    "            torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')\n",
    "    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    # Change here to adapt to your data\n",
    "    # n_channels=3 for RGB images\n",
    "    # n_classes is the number of probabilities you want to get per pixel\n",
    "    model = UNet(n_channels=3, n_classes=args.classes, bilinear=args.bilinear)\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    logging.info(f'Network:\\n'\n",
    "                 f'\\t{model.n_channels} input channels\\n'\n",
    "                 f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "    if args.load:\n",
    "        state_dict = torch.load(args.load, map_location=device)\n",
    "        del state_dict['mask_values']\n",
    "        model.load_state_dict(state_dict)\n",
    "        logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "    model.to(device=device)\n",
    "    try:\n",
    "        train_model(\n",
    "            model=model,\n",
    "            epochs=args.epochs,\n",
    "            batch_size=args.batch_size,\n",
    "            learning_rate=args.lr,\n",
    "            device=device,\n",
    "            img_scale=args.scale,\n",
    "            val_percent=args.val / 100,\n",
    "            amp=args.amp\n",
    "        )\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        logging.error('Detected OutOfMemoryError! '\n",
    "                      'Enabling checkpointing to reduce memory usage, but this slows down training. '\n",
    "                      'Consider enabling AMP (--amp) for fast and memory efficient training')\n",
    "        torch.cuda.empty_cache()\n",
    "        model.use_checkpointing()\n",
    "        train_model(\n",
    "            model=model,\n",
    "            epochs=args.epochs,\n",
    "            batch_size=args.batch_size,\n",
    "            learning_rate=args.lr,\n",
    "            device=device,\n",
    "            img_scale=args.scale,\n",
    "            val_percent=args.val / 100,\n",
    "            amp=args.amp\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DICOM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
